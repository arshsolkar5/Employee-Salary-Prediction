{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cbeJSiSOSm4e"
      },
      "outputs": [],
      "source": [
        "# Cell 1: Install required libraries\n",
        "!pip install -q streamlit plotly joblib fpdf xgboost pyngrok\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from xgboost import XGBRegressor\n",
        "import os\n"
      ],
      "metadata": {
        "id": "JjWDL4weS-Xr"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: Upload dataset (Colab or Jupyter)\n",
        "import pandas as pd\n",
        "import io\n",
        "\n",
        "try:\n",
        "    from google.colab import files\n",
        "    uploaded = files.upload()\n",
        "    for fn in uploaded.keys():\n",
        "        df = pd.read_csv(io.BytesIO(uploaded[fn]))\n",
        "        print(f\"âœ… Loaded: {fn}\")\n",
        "        break\n",
        "except ImportError:\n",
        "    # Jupyter\n",
        "    import ipywidgets as widgets\n",
        "    from IPython.display import display\n",
        "\n",
        "    upload = widgets.FileUpload(accept='.csv', multiple=False)\n",
        "    display(upload)\n",
        "\n",
        "    def handle_upload(change):\n",
        "        if upload.value:\n",
        "            name = list(upload.value.keys())[0]\n",
        "            content = upload.value[name]['content']\n",
        "            global df\n",
        "            df = pd.read_csv(io.BytesIO(content))\n",
        "            print(f\"âœ… Loaded: {name}\")\n",
        "            display(df.head())\n",
        "\n",
        "    upload.observe(handle_upload, names='value')\n"
      ],
      "metadata": {
        "id": "7DgDfAQlTEh4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4: Preprocess data and save encoders\n",
        "categorical_cols = ['Gender', 'Education', 'Department', 'JobTitle']\n",
        "encoders = {}\n",
        "encoder_classes = {}\n",
        "\n",
        "for col in categorical_cols:\n",
        "    le = LabelEncoder()\n",
        "    df[col] = le.fit_transform(df[col])\n",
        "    encoders[col] = le\n",
        "    encoder_classes[col] = le.classes_.tolist()  # Save for decoding later\n",
        "\n",
        "X = df.drop(['EmployeeID', 'Salary'], axis=1)\n",
        "y = df['Salary']\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Save all artifacts\n",
        "joblib.dump(feature_columns := X.columns.tolist(), \"feature_columns.pkl\")\n",
        "joblib.dump(scaler, \"scaler.pkl\")\n",
        "joblib.dump(encoders, \"encoders.pkl\")\n",
        "joblib.dump(encoder_classes, \"encoder_classes.pkl\")\n"
      ],
      "metadata": {
        "id": "oGypbf7aTG0I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5: Train models and save\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from xgboost import XGBRegressor\n",
        "import joblib\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# âœ… Save training data to display RÂ² scores in Streamlit app\n",
        "joblib.dump(X_train, \"X_scaled_train.pkl\")\n",
        "joblib.dump(y_train, \"y_train.pkl\")\n",
        "\n",
        "# Train models\n",
        "models = {\n",
        "    'LinearRegression': LinearRegression(),\n",
        "    'RandomForest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
        "    'XGBoost': XGBRegressor(n_estimators=100, random_state=42)\n",
        "}\n",
        "\n",
        "# Fit and save each model\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    joblib.dump(model, f\"{name}_model.pkl\")\n",
        "\n"
      ],
      "metadata": {
        "id": "yvL5r3yhTdRR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "from datetime import datetime\n",
        "import shap\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import r2_score\n",
        "import plotly.graph_objs as go\n",
        "\n",
        "st.set_page_config(page_title=\"Salary Predictor\", layout=\"wide\")\n",
        "\n",
        "# Load artifacts\n",
        "scaler = joblib.load(\"scaler.pkl\")\n",
        "encoders = joblib.load(\"encoders.pkl\")\n",
        "feature_columns = joblib.load(\"feature_columns.pkl\")\n",
        "encoder_classes = joblib.load(\"encoder_classes.pkl\")\n",
        "\n",
        "models = {\n",
        "    \"Linear Regression\": joblib.load(\"LinearRegression_model.pkl\"),\n",
        "    \"Random Forest\": joblib.load(\"RandomForest_model.pkl\"),\n",
        "    \"XGBoost\": joblib.load(\"XGBoost_model.pkl\")\n",
        "}\n",
        "\n",
        "# Sidebar\n",
        "st.sidebar.title(\"Salary Predictor\")\n",
        "model_name = st.sidebar.selectbox(\"Choose a model\", list(models.keys()))\n",
        "\n",
        "# Title\n",
        "st.title(\"ðŸ’¼ Employee Salary Prediction App\")\n",
        "\n",
        "uploaded_file = st.file_uploader(\"ðŸ“‚ Upload Employee Dataset (CSV)\", type=[\"csv\"])\n",
        "if uploaded_file is not None:\n",
        "    df = pd.read_csv(uploaded_file)\n",
        "    st.success(\"âœ… Dataset successfully uploaded!\")\n",
        "    st.write(\"Preview of Uploaded Data:\", df.head())\n",
        "\n",
        "with st.form(\"input_form\"):\n",
        "    st.subheader(\"ðŸ“ Enter Employee Information\")\n",
        "    col1, col2 = st.columns(2)\n",
        "\n",
        "    with col1:\n",
        "        Gender = st.selectbox(\"Gender\", encoders['Gender'].classes_)\n",
        "        Education = st.selectbox(\"Education\", encoders['Education'].classes_)\n",
        "        Department = st.selectbox(\"Department\", encoders['Department'].classes_)\n",
        "        JobTitle = st.selectbox(\"Job Title\", encoders['JobTitle'].classes_)\n",
        "\n",
        "    with col2:\n",
        "        Age = st.number_input(\"Age\", min_value=18, max_value=65, value=30)\n",
        "        WorkExperience = st.number_input(\"Work Experience\", min_value=0, max_value=40, value=5)\n",
        "        PerformanceScore = st.number_input(\"Performance Score\", min_value=1.0, max_value=5.0, value=3.0)\n",
        "        Certifications = st.number_input(\"Certifications\", min_value=0, max_value=10, value=2)\n",
        "        ProjectsHandled = st.number_input(\"Projects Handled\", min_value=0, max_value=50, value=5)\n",
        "        PreviousCompanyRating = st.number_input(\"Previous Company Rating\", min_value=1.0, max_value=5.0, value=3.0)\n",
        "\n",
        "    submit = st.form_submit_button(\"ðŸš€ Predict Salary\")\n",
        "\n",
        "if submit:\n",
        "    input_data_encoded = {\n",
        "        'Gender': encoders['Gender'].transform([Gender])[0],\n",
        "        'Education': encoders['Education'].transform([Education])[0],\n",
        "        'Department': encoders['Department'].transform([Department])[0],\n",
        "        'JobTitle': encoders['JobTitle'].transform([JobTitle])[0],\n",
        "        'Age': Age,\n",
        "        'WorkExperience': WorkExperience,\n",
        "        'PerformanceScore': PerformanceScore,\n",
        "        'Certifications': Certifications,\n",
        "        'ProjectsHandled': ProjectsHandled,\n",
        "        'PreviousCompanyRating': PreviousCompanyRating\n",
        "    }\n",
        "\n",
        "    input_df = pd.DataFrame([input_data_encoded])\n",
        "    input_scaled = scaler.transform(input_df[feature_columns])\n",
        "    model = models[model_name]\n",
        "    prediction = model.predict(input_scaled)[0]\n",
        "\n",
        "    # Prepare user-friendly display result\n",
        "    display_data = {\n",
        "        'Gender': Gender,\n",
        "        'Education': Education,\n",
        "        'Department': Department,\n",
        "        'JobTitle': JobTitle,\n",
        "        'Age': Age,\n",
        "        'WorkExperience': WorkExperience,\n",
        "        'PerformanceScore': PerformanceScore,\n",
        "        'Certifications': Certifications,\n",
        "        'ProjectsHandled': ProjectsHandled,\n",
        "        'PreviousCompanyRating': PreviousCompanyRating,\n",
        "        'Predicted Salary': prediction\n",
        "    }\n",
        "    result_df = pd.DataFrame([display_data])\n",
        "\n",
        "    st.subheader(\"ðŸ“Š Prediction Result\")\n",
        "    st.dataframe(result_df.style.format({'Predicted Salary': '${:,.2f}'}), use_container_width=True)\n",
        "\n",
        "    # Explain prediction with SHAP\n",
        "    st.subheader(\"ðŸ” Explanation of Prediction (SHAP Values)\")\n",
        "\n",
        "    X_train_shap = joblib.load(\"X_scaled_train.pkl\")\n",
        "    X_train_df = pd.DataFrame(X_train_shap, columns=feature_columns)\n",
        "    input_df_named = pd.DataFrame(input_scaled, columns=feature_columns)\n",
        "\n",
        "    explainer = shap.Explainer(model, X_train_df)\n",
        "    shap_values = explainer(input_df_named)\n",
        "\n",
        "    st.markdown(\"#### Top Factors Influencing This Prediction\")\n",
        "    top_features = np.argsort(-np.abs(shap_values.values[0]))[:5]\n",
        "    for i in top_features:\n",
        "        feature_name = feature_columns[i]\n",
        "        impact = shap_values.values[0][i]\n",
        "        sign = \"increased\" if impact > 0 else \"decreased\"\n",
        "        st.write(f\"- **{feature_name}** {sign} predicted salary by **${abs(impact):,.2f}**\")\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(8, 4))\n",
        "    shap.plots.bar(shap_values, max_display=10, show=False)\n",
        "    st.pyplot(fig)\n",
        "\n",
        "        # ---------------------- Model Configuration & Accuracy ---------------------- #\n",
        "    st.subheader(\"âš™ï¸ Model Configuration & Performance\")\n",
        "\n",
        "    # Load training data to calculate RÂ² scores\n",
        "    y_train = joblib.load(\"y_train.pkl\")\n",
        "    model_scores = {}\n",
        "\n",
        "    for name, m in models.items():\n",
        "        y_pred_train = m.predict(X_train_shap)\n",
        "        score = r2_score(y_train, y_pred_train)\n",
        "        model_scores[name] = round(score, 4)\n",
        "\n",
        "    # Gauge-like plot for the selected model\n",
        "    selected_score = model_scores[model_name]\n",
        "    fig_gauge = go.Figure(go.Indicator(\n",
        "        mode=\"gauge+number\",\n",
        "        value=selected_score * 100,\n",
        "        title={'text': f\"{model_name} RÂ² Score (%)\"},\n",
        "        gauge={\n",
        "            'axis': {'range': [0, 100]},\n",
        "            'bar': {'color': \"#00cc96\"},\n",
        "            'steps': [\n",
        "                {'range': [0, 50], 'color': \"#ffe6e6\"},\n",
        "                {'range': [50, 75], 'color': \"#ffffcc\"},\n",
        "                {'range': [75, 100], 'color': \"#e6ffe6\"},\n",
        "            ],\n",
        "        }\n",
        "    ))\n",
        "    st.plotly_chart(fig_gauge, use_container_width=True)\n",
        "\n",
        "    # Accuracy comparison table\n",
        "    st.markdown(\"### ðŸ“ˆ Model Accuracy Comparison (on training set)\")\n",
        "    accuracy_df = pd.DataFrame.from_dict(model_scores, orient='index', columns=[\"RÂ² Score\"])\n",
        "    st.dataframe(accuracy_df.style.format({\"RÂ² Score\": \"{:.2%}\"}), use_container_width=True)\n",
        "\n",
        "    # Performance interpretation\n",
        "    st.markdown(\"### ðŸ“‹ Model Performance \")\n",
        "    for name, score in model_scores.items():\n",
        "        interpretation = \"\"\n",
        "        if score >= 0.9:\n",
        "            interpretation = \" Excellent performance â€“ fits data very well.\"\n",
        "        elif score >= 0.75:\n",
        "            interpretation = \" Good performance â€“ suitable for predictions.\"\n",
        "        elif score >= 0.6:\n",
        "            interpretation = \" Moderate â€“ might underperform on complex data.\"\n",
        "        else:\n",
        "            interpretation = \" Low â€“ not recommended unless improved.\"\n",
        "\n",
        "        st.markdown(f\"**{name}**: RÂ² = **{score:.2%}** â€“ {interpretation}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zj1eQmiGTgqz",
        "outputId": "662f184c-ce91-48be-fcb5-ef6e74b49471"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "ngrok.set_auth_token(\"Your Auth Token Here\")"
      ],
      "metadata": {
        "id": "ATEioR68TzhN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b8f6f8c-9e92-4ce7-e3be-12dce434f09d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 7: \n",
        "from pyngrok import ngrok\n",
        "!streamlit run app.py &>/content/logs.txt &  # For Colab\n",
        "url = ngrok.connect(8501)\n",
        "print(\"Public URL:\", url)\n"
      ],
      "metadata": {
        "id": "vafgn4nTTj5Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pkill -f streamlit\n",
        "!pkill -f ngrok\n"
      ],
      "metadata": {
        "id": "PxhcKywmTnOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rkmKWSxYXlVt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
